"""
ğŸ¤– Life Coach LINE Bot - Stable Edition
========================================
Ù†Ø³Ø®Ø© Ù…Ø³ØªÙ‚Ø±Ø© ÙˆÙ…Ø®ØªØ¨Ø±Ø©
"""

from flask import Flask, request, abort, jsonify
from linebot.v3 import WebhookHandler
from linebot.v3.exceptions import InvalidSignatureError
from linebot.v3.messaging import (
    Configuration, ApiClient, MessagingApi,
    ReplyMessageRequest, TextMessage
)
from linebot.v3.webhooks import MessageEvent, TextMessageContent, FollowEvent
import google.generativeai as genai
import os
from datetime import datetime, timedelta
from collections import defaultdict, deque
import logging
import time

# ================== Logging ==================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s'
)
logger = logging.getLogger(__name__)

# ================== Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ==================
app = Flask(__name__)

# ================== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª LINE ==================
LINE_CHANNEL_ACCESS_TOKEN = os.getenv('LINE_CHANNEL_ACCESS_TOKEN')
LINE_CHANNEL_SECRET = os.getenv('LINE_CHANNEL_SECRET')

configuration = Configuration(access_token=LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

# ================== Ù…ÙØ§ØªÙŠØ­ Gemini ==================
GEMINI_KEYS = [
    os.getenv('GEMINI_API_KEY_1'),
    os.getenv('GEMINI_API_KEY_2'),
    os.getenv('GEMINI_API_KEY_3')
]
GEMINI_KEYS = [k for k in GEMINI_KEYS if k and not k.startswith('your_')]

logger.info(f"ğŸ”‘ Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ù…ØªØ§Ø­Ø©: {len(GEMINI_KEYS)}")

# ================== Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¨Ø³ÙŠØ·Ø© ==================
class SimpleMemory:
    def __init__(self):
        self.conversations = defaultdict(lambda: deque(maxlen=6))
        
    def add_message(self, user_id: str, role: str, content: str):
        self.conversations[user_id].append({
            'role': role,
            'content': content[:100]  # Ø§Ø­ØªÙØ¸ Ø¨Ù€ 100 Ø­Ø±Ù ÙÙ‚Ø·
        })
        
    def get_history(self, user_id: str) -> str:
        history = list(self.conversations[user_id])[-3:]
        if not history:
            return ""
        
        formatted = []
        for msg in history:
            role = "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…" if msg['role'] == 'user' else "Ø£Ù†ØªÙ"
            formatted.append(f"{role}: {msg['content']}")
        return "\n".join(formatted)

# ================== Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…ÙØ§ØªÙŠØ­ ==================
class KeyManager:
    def __init__(self, keys):
        self.keys = keys
        self.current_index = 0
        self.failed_keys = set()
        
    def get_next_key(self):
        attempts = 0
        while attempts < len(self.keys):
            if self.current_index not in self.failed_keys:
                key = self.keys[self.current_index]
                key_index = self.current_index
                self.current_index = (self.current_index + 1) % len(self.keys)
                return key, key_index
            
            self.current_index = (self.current_index + 1) % len(self.keys)
            attempts += 1
        
        raise Exception("Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ ÙØ´Ù„Øª")
    
    def mark_failed(self, key_index: int):
        self.failed_keys.add(key_index)
        logger.warning(f"âŒ Ø§Ù„Ù…ÙØªØ§Ø­ {key_index + 1} ÙØ´Ù„")

# ================== ØªÙ‡ÙŠØ¦Ø© ==================
memory = SimpleMemory()
key_manager = KeyManager(GEMINI_KEYS)

# ================== Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ (Ù…Ø±ØªØ¨Ø© Ø­Ø³Ø¨ Ø§Ù„Ø£ÙØ¶Ù„ÙŠØ©) ==================
MODELS_TO_TRY = [
    'gemini-1.5-flash',
    'gemini-1.5-flash-latest',
    'gemini-pro',
    'gemini-1.5-pro-latest'
]

# ================== Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¹Ù…Ù„ ==================
def find_working_model():
    """ÙŠØ¨Ø­Ø« Ø¹Ù† Ø£ÙˆÙ„ Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¹Ù…Ù„"""
    for key_idx in range(len(GEMINI_KEYS)):
        try:
            key = GEMINI_KEYS[key_idx]
            genai.configure(api_key=key)
            
            for model_name in MODELS_TO_TRY:
                try:
                    logger.info(f"ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø±: {model_name} Ù…Ø¹ Ø§Ù„Ù…ÙØªØ§Ø­ {key_idx + 1}")
                    
                    model = genai.GenerativeModel(model_name)
                    response = model.generate_content(
                        "Hi",
                        generation_config=genai.types.GenerationConfig(
                            max_output_tokens=10,
                            temperature=0.9
                        )
                    )
                    
                    if response.text:
                        logger.info(f"âœ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {model_name} ÙŠØ¹Ù…Ù„!")
                        return model_name, key_idx
                        
                except Exception as e:
                    error_str = str(e).lower()
                    if "404" in error_str:
                        logger.info(f"â­ï¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {model_name} ØºÙŠØ± Ù…ØªÙˆÙØ±")
                        continue
                    elif "quota" in error_str or "limit" in error_str:
                        logger.warning(f"âš ï¸ Ø§Ù„Ù…ÙØªØ§Ø­ {key_idx + 1} ÙˆØµÙ„ Ù„Ù„Ø­Ø¯")
                        break
                    else:
                        logger.error(f"âŒ Ø®Ø·Ø£: {str(e)[:100]}")
                        continue
                        
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…ÙØªØ§Ø­ {key_idx + 1}: {str(e)[:100]}")
            continue
    
    return None, None

# Ø§Ø¨Ø­Ø« Ø¹Ù† Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¹Ù…Ù„ Ø¹Ù†Ø¯ Ø§Ù„Ø¨Ø¯Ø¡
WORKING_MODEL = None
WORKING_KEY_INDEX = None

try:
    logger.info("ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¹Ù…Ù„...")
    WORKING_MODEL, WORKING_KEY_INDEX = find_working_model()
    
    if WORKING_MODEL:
        logger.info(f"ğŸ‰ ØªÙ…! Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {WORKING_MODEL} | Ø§Ù„Ù…ÙØªØ§Ø­: {WORKING_KEY_INDEX + 1}")
    else:
        logger.error("âŒ Ù„Ù… Ù†Ø¬Ø¯ Ø£ÙŠ Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¹Ù…Ù„!")
except Exception as e:
    logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«: {e}")

# ================== Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ==================
def get_ai_response(user_id: str, message: str) -> str:
    """ÙŠØ­ØµÙ„ Ø¹Ù„Ù‰ Ø±Ø¯ Ù…Ù† Gemini"""
    
    if not WORKING_MODEL:
        return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø§Ù„Ø®Ø¯Ù…Ø© ØºÙŠØ± Ù…ØªØ§Ø­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹. Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù„Ù‰ Ø­Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© ğŸ”§"
    
    # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø³ÙŠØ§Ù‚
    history = memory.get_history(user_id)
    
    prompt = f"""Ø£Ù†Øª "Ù†ÙˆØ±" - Ù…Ø¯Ø±Ø¨Ø© Ø­ÙŠØ§Ø© Ø´Ø®ØµÙŠØ© ÙˆØ¯ÙˆØ¯Ø©.

{"Ø¢Ø®Ø± Ø±Ø³Ø§Ø¦Ù„:" if history else ""}
{history}

Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {message}

Ø±Ø¯ Ø¨Ù€ 2-3 Ø¬Ù…Ù„ ÙÙ‚Ø·ØŒ ÙƒÙˆÙ†ÙŠ Ø·Ø¨ÙŠØ¹ÙŠØ© ÙˆØ¯Ø§ÙØ¦Ø©. Ø¨Ø¯ÙˆÙ† Ø¥ÙŠÙ…ÙˆØ¬ÙŠ."""

    # Ø¬Ø±Ø¨ Ù…Ø¹ Ø§Ù„Ù…ÙØªØ§Ø­ ÙˆØ§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ÙŠ Ø´ØºØ§Ù„ÙŠÙ†
    for attempt in range(3):
        try:
            logger.info(f"ğŸ”„ Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}/3")
            
            key = GEMINI_KEYS[WORKING_KEY_INDEX]
            genai.configure(api_key=key)
            
            model = genai.GenerativeModel(
                WORKING_MODEL,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.9,
                    top_p=0.95,
                    max_output_tokens=200,
                )
            )
            
            response = model.generate_content(prompt)
            reply = response.text.strip()
            
            # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            memory.add_message(user_id, 'user', message)
            memory.add_message(user_id, 'assistant', reply)
            
            logger.info(f"âœ… Ø±Ø¯ Ù†Ø§Ø¬Ø­!")
            return reply
            
        except Exception as e:
            error_msg = str(e).lower()
            logger.error(f"âŒ Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1} ÙØ´Ù„Øª: {str(e)[:100]}")
            
            if "quota" in error_msg or "limit" in error_msg or "resource" in error_msg:
                return "ÙˆØµÙ„Ù†Ø§ Ù„Ù„Ø­Ø¯ Ø§Ù„ÙŠÙˆÙ…ÙŠ ğŸ˜Š Ø¬Ø±Ø¨ÙŠ ØºØ¯Ø§Ù‹ Ø£Ùˆ ØªÙˆØ§ØµÙ„ÙŠ Ù…Ø¹ Ø§Ù„Ù…Ø·ÙˆØ± Ù„Ø¥Ø¶Ø§ÙØ© Ù…ÙØ§ØªÙŠØ­"
            
            if attempt < 2:
                time.sleep(1)
                continue
            else:
                return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­ØµÙ„ Ø®Ø·Ø£ Ù…Ø¤Ù‚Øª. Ø¬Ø±Ø¨ÙŠ Ù…Ø±Ø© Ø«Ø§Ù†ÙŠØ© ğŸŒ¸"
    
    return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹ Ø§Ù„Ø±Ø¯ Ø§Ù„Ø¢Ù† ğŸ’­"

# ================== Ù…Ø¹Ø§Ù„Ø¬Ø§Øª LINE ==================
@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers.get('X-Line-Signature', '')
    body = request.get_data(as_text=True)
    
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        logger.error("Invalid signature")
        abort(400)
    except Exception as e:
        logger.error(f"Callback error: {e}")
        abort(500)
    
    return 'OK'

@handler.add(MessageEvent, message=TextMessageContent)
def handle_message(event):
    try:
        user_id = event.source.user_id
        message = event.message.text.strip()
        
        logger.info(f"ğŸ“¨ Ù…Ù† {user_id[:8]}: {message[:50]}")
        
        reply = get_ai_response(user_id, message)
        
        with ApiClient(configuration) as api_client:
            line_bot_api = MessagingApi(api_client)
            line_bot_api.reply_message(
                ReplyMessageRequest(
                    reply_token=event.reply_token,
                    messages=[TextMessage(text=reply)]
                )
            )
        
        logger.info(f"âœ… Ø±Ø¯ Ù…Ø±Ø³Ù„")
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£: {e}")

@handler.add(FollowEvent)
def handle_follow(event):
    user_id = event.source.user_id
    logger.info(f"ğŸ‰ Ù…ØªØ§Ø¨Ø¹ Ø¬Ø¯ÙŠØ¯: {user_id}")
    
    welcome = """Ù…Ø±Ø­Ø¨Ø§Ù‹! Ø£Ù†Ø§ Ù†ÙˆØ± ğŸŒŸ

Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ø£Ø¯Ø¹Ù…Ùƒ ÙÙŠ Ø±Ø­Ù„ØªÙƒ.
Ø´Ø§Ø±ÙƒÙŠÙ†ÙŠ Ø£ÙŠ Ø´ÙŠØ¡ ÙÙŠ Ø¨Ø§Ù„Ùƒ."""
    
    try:
        with ApiClient(configuration) as api_client:
            line_bot_api = MessagingApi(api_client)
            line_bot_api.reply_message(
                ReplyMessageRequest(
                    reply_token=event.reply_token,
                    messages=[TextMessage(text=welcome)]
                )
            )
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ±Ø­ÙŠØ¨: {e}")

# ================== Ù†Ù‚Ø§Ø· Ø§Ù„Ù†Ù‡Ø§ÙŠØ© ==================
@app.route("/", methods=['GET'])
def home():
    return jsonify({
        'status': 'running',
        'bot': 'Life Coach Bot',
        'model': WORKING_MODEL or 'none',
        'key_index': WORKING_KEY_INDEX + 1 if WORKING_KEY_INDEX is not None else 0,
        'users': len(memory.conversations)
    })

@app.route("/health", methods=['GET'])
def health():
    return jsonify({
        'status': 'healthy' if WORKING_MODEL else 'degraded',
        'model': WORKING_MODEL,
        'timestamp': datetime.now().isoformat()
    })

@app.route("/test", methods=['GET'])
def test_endpoint():
    """Ù†Ù‚Ø·Ø© Ø§Ø®ØªØ¨Ø§Ø± Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø´ÙƒÙ„Ø©"""
    try:
        result = find_working_model()
        return jsonify({
            'success': result[0] is not None,
            'model': result[0],
            'key_index': result[1],
            'available_keys': len(GEMINI_KEYS),
            'models_tried': MODELS_TO_TRY
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ================== Ø§Ù„ØªØ´ØºÙŠÙ„ ==================
if __name__ == "__main__":
    logger.info("ğŸš€ Life Coach Bot - Stable")
    logger.info(f"ğŸ“Š Ù…ÙØ§ØªÙŠØ­: {len(GEMINI_KEYS)}")
    logger.info(f"ğŸ¤– Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {WORKING_MODEL or 'Ù„Ø§ ÙŠÙˆØ¬Ø¯'}")
    
    port = int(os.getenv('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)
