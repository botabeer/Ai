"""
ğŸ¤– Life Coach LINE Bot - Ultra Simple & Stable
===============================================
âœ… Ù†Ø³Ø®Ø© Ù…Ø­Ø¯Ø«Ø© Ù„Ù€ Gemini 2026 Models
"""

from flask import Flask, request, abort, jsonify
from linebot.v3 import WebhookHandler
from linebot.v3.exceptions import InvalidSignatureError
from linebot.v3.messaging import (
    Configuration, ApiClient, MessagingApi,
    ReplyMessageRequest, TextMessage
)
from linebot.v3.webhooks import MessageEvent, TextMessageContent, FollowEvent
import google.generativeai as genai
import os
from collections import defaultdict, deque
import logging

# ================== Setup ==================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# ================== Config ==================
LINE_CHANNEL_ACCESS_TOKEN = os.getenv('LINE_CHANNEL_ACCESS_TOKEN')
LINE_CHANNEL_SECRET = os.getenv('LINE_CHANNEL_SECRET')

if not LINE_CHANNEL_ACCESS_TOKEN or not LINE_CHANNEL_SECRET:
    logger.error("âŒ Missing LINE credentials!")
    raise ValueError("LINE credentials not found in environment")

configuration = Configuration(access_token=LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

# Gemini Keys
GEMINI_KEYS = [
    os.getenv('GEMINI_API_KEY_1'),
    os.getenv('GEMINI_API_KEY_2'),
    os.getenv('GEMINI_API_KEY_3')
]
GEMINI_KEYS = [k for k in GEMINI_KEYS if k and not k.startswith('your_')]

if not GEMINI_KEYS:
    logger.error("âŒ No valid Gemini API keys!")
    raise ValueError("At least one Gemini API key is required")

logger.info(f"ğŸ”‘ Loaded {len(GEMINI_KEYS)} Gemini API key(s)")

# ================== Memory ==================
class Memory:
    def __init__(self):
        self.chats = defaultdict(lambda: deque(maxlen=4))
    
    def add(self, user_id, role, msg):
        self.chats[user_id].append({'role': role, 'msg': msg[:80]})
    
    def get(self, user_id):
        h = list(self.chats[user_id])[-2:]
        if not h:
            return ""
        return "\n".join([f"{'Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…' if m['role']=='user' else 'Ù†ÙˆØ±'}: {m['msg']}" for m in h])

memory = Memory()

# ================== AI Response ==================
def get_reply(user_id, message):
    """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯"""
    
    if not GEMINI_KEYS:
        return "âš ï¸ Ø§Ù„Ø¨ÙˆØª ØºÙŠØ± Ù…Ù‡ÙŠØ£"
    
    # âœ… Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØµØ­ÙŠØ­Ø© Ù„Ù†Ù…Ø§Ø°Ø¬ Gemini 2026
    # Ù…Ù† Ø§Ù„Ø£Ø³Ø±Ø¹ ÙˆØ§Ù„Ø£Ø±Ø®Øµ Ø¥Ù„Ù‰ Ø§Ù„Ø£Ù‚ÙˆÙ‰
    models = [
        'gemini-2.0-flash-exp',      # Ø£Ø³Ø±Ø¹ ÙˆØ£Ø±Ø®Øµ (ØªØ¬Ø±ÙŠØ¨ÙŠ)
        'gemini-2.0-flash',           # Ø³Ø±ÙŠØ¹ ÙˆÙ…Ø³ØªÙ‚Ø±
        'gemini-1.5-flash-latest',    # Ù…ØªÙˆÙØ± Ù„Ù„Ø¬Ù…ÙŠØ¹
        'gemini-1.5-pro-latest',      # Ø£Ù‚ÙˆÙ‰ Ù„ÙƒÙ† Ø£Ø¨Ø·Ø£
    ]
    
    history = memory.get(user_id)
    prompt = f"""Ø£Ù†Øª Ù†ÙˆØ±ØŒ Ù…Ø¯Ø±Ø¨Ø© Ø­ÙŠØ§Ø© ÙˆØ¯ÙˆØ¯Ø©. Ø±Ø¯ Ø¨Ù€ 2-3 Ø¬Ù…Ù„.

{f"Ù…Ø­Ø§Ø¯Ø«Ø© Ø³Ø§Ø¨Ù‚Ø©:\n{history}\n" if history else ""}
Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {message}

Ø±Ø¯Ùƒ:"""

    last_error = None
    
    # Try all keys and models
    for key_idx, key in enumerate(GEMINI_KEYS):
        logger.info(f"ğŸ”‘ Trying key #{key_idx+1}")
        
        try:
            genai.configure(api_key=key)
            
            for model_name in models:
                try:
                    logger.info(f"ğŸ¤– Trying model: {model_name}")
                    
                    model = genai.GenerativeModel(model_name)
                    response = model.generate_content(
                        prompt,
                        generation_config=genai.types.GenerationConfig(
                            temperature=0.9,
                            max_output_tokens=150
                        )
                    )
                    
                    if response and response.text:
                        reply = response.text.strip()
                        memory.add(user_id, 'user', message)
                        memory.add(user_id, 'assistant', reply)
                        logger.info(f"âœ… SUCCESS with key #{key_idx+1}, model: {model_name}")
                        return reply
                
                except Exception as model_error:
                    error_str = str(model_error)
                    error_lower = error_str.lower()
                    
                    # Log the ACTUAL error
                    logger.error(f"âŒ Key #{key_idx+1}, Model {model_name} FAILED:")
                    logger.error(f"   Error: {error_str[:200]}")
                    
                    last_error = error_str
                    
                    # Check if quota/limit issue
                    if any(x in error_lower for x in ["quota", "limit", "resource", "exhausted"]):
                        logger.warning(f"âš ï¸ Key #{key_idx+1} QUOTA EXCEEDED, trying next key...")
                        break  # Try next key
                    
                    # Check if invalid API key
                    if any(x in error_lower for x in ["invalid", "api_key", "unauthorized", "403"]):
                        logger.error(f"ğŸš« Key #{key_idx+1} is INVALID!")
                        break  # Try next key
                    
                    # Check if model not found
                    if "404" in error_lower or "not found" in error_lower:
                        logger.warning(f"âš ï¸ Model {model_name} not available, trying next model...")
                        continue  # Try next model
                    
                    # Unknown error, try next model
                    continue
        
        except Exception as key_error:
            logger.error(f"âŒ Key #{key_idx+1} CONFIGURATION FAILED: {key_error}")
            continue
    
    # All attempts failed
    logger.error("="*60)
    logger.error("âŒ ALL KEYS AND MODELS EXHAUSTED!")
    if last_error:
        logger.error(f"Last error: {last_error[:300]}")
    logger.error("="*60)
    
    return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ø§ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ø±Ø¯ Ø§Ù„Ø¢Ù† ğŸ˜”\nØ¬Ø±Ø¨ÙŠ Ø¨Ø¹Ø¯ Ù‚Ù„ÙŠÙ„ ğŸ’­"

# ================== LINE Handlers ==================
@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers.get('X-Line-Signature', '')
    body = request.get_data(as_text=True)
    
    logger.info(f"ğŸ“¨ Received webhook request")
    
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        logger.error("âŒ Invalid signature")
        abort(400)
    except Exception as e:
        logger.error(f"âŒ Webhook error: {e}")
        abort(500)
    
    return 'OK'

@handler.add(MessageEvent, message=TextMessageContent)
def handle_message(event):
    try:
        user_id = event.source.user_id
        message = event.message.text.strip()
        
        logger.info(f"ğŸ“© Message from {user_id[:8]}...: {message[:40]}")
        
        # Generate reply
        reply = get_reply(user_id, message)
        logger.info(f"ğŸ’¬ Reply: {reply[:40]}")
        
        # Send reply
        with ApiClient(configuration) as api_client:
            line_bot_api = MessagingApi(api_client)
            line_bot_api.reply_message(
                ReplyMessageRequest(
                    reply_token=event.reply_token,
                    messages=[TextMessage(text=reply)]
                )
            )
        
        logger.info("âœ… Reply sent successfully")
        
    except Exception as e:
        logger.error(f"âŒ Error handling message: {e}", exc_info=True)

@handler.add(FollowEvent)
def handle_follow(event):
    welcome = "Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ! Ø£Ù†Ø§ Ù†ÙˆØ± ğŸŒŸ\n\nÙ…Ø¯Ø±Ø¨ØªÙƒ Ø§Ù„Ø´Ø®ØµÙŠØ© Ù‡Ù†Ø§ Ù„Ø¯Ø¹Ù…Ùƒ.\nØ´Ø§Ø±ÙƒÙŠÙ†ÙŠ Ù…Ø§ ÙÙŠ Ø¨Ø§Ù„Ùƒ ğŸ’­"
    
    try:
        logger.info(f"ğŸ‘‹ New follower: {event.source.user_id[:8]}...")
        
        with ApiClient(configuration) as api_client:
            line_bot_api = MessagingApi(api_client)
            line_bot_api.reply_message(
                ReplyMessageRequest(
                    reply_token=event.reply_token,
                    messages=[TextMessage(text=welcome)]
                )
            )
        
        logger.info("âœ… Welcome message sent")
        
    except Exception as e:
        logger.error(f"âŒ Error sending welcome: {e}")

# ================== Health Endpoints ==================
@app.route("/")
def home():
    return jsonify({
        'status': 'ok',
        'bot': 'Life Coach Bot',
        'version': '2.0'
    }), 200

@app.route("/health")
def health():
    return jsonify({
        'status': 'healthy',
        'gemini_keys': len(GEMINI_KEYS)
    }), 200

@app.route("/ping")
def ping():
    return "pong", 200

# ================== Test Endpoints ==================
@app.route("/test-gemini")
def test_gemini():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±ÙŠØ¹ Ù„Ù…ÙØ§ØªÙŠØ­ Gemini"""
    results = []
    
    test_models = [
        'gemini-2.0-flash-exp',
        'gemini-2.0-flash',
        'gemini-1.5-flash-latest',
        'gemini-1.5-pro-latest'
    ]
    
    for idx, key in enumerate(GEMINI_KEYS):
        key_result = {'key': f"Key #{idx+1}", 'models': []}
        
        try:
            genai.configure(api_key=key)
            
            for model_name in test_models:
                try:
                    model = genai.GenerativeModel(model_name)
                    response = model.generate_content(
                        "Ù…Ø±Ø­Ø¨Ø§",
                        generation_config=genai.types.GenerationConfig(
                            max_output_tokens=10
                        )
                    )
                    
                    key_result['models'].append({
                        'name': model_name,
                        'status': 'âœ… working',
                        'sample': response.text[:30]
                    })
                    
                except Exception as e:
                    key_result['models'].append({
                        'name': model_name,
                        'status': 'âŒ failed',
                        'error': str(e)[:100]
                    })
            
            results.append(key_result)
            
        except Exception as e:
            results.append({
                'key': f"Key #{idx+1}",
                'status': 'failed',
                'error': str(e)[:100]
            })
    
    return jsonify(results), 200

@app.route("/list-models")
def list_models():
    """Ø¹Ø±Ø¶ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©"""
    if not GEMINI_KEYS:
        return jsonify({'error': 'No API keys'}), 400
    
    try:
        genai.configure(api_key=GEMINI_KEYS[0])
        models = genai.list_models()
        
        available = []
        for m in models:
            if 'generateContent' in m.supported_generation_methods:
                available.append({
                    'name': m.name,
                    'display_name': m.display_name,
                    'description': m.description
                })
        
        return jsonify({
            'total': len(available),
            'models': available
        }), 200
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# ================== Startup ==================
logger.info("="*60)
logger.info("ğŸš€ Life Coach Bot Starting...")
logger.info(f"ğŸ”‘ Gemini Keys: {len(GEMINI_KEYS)}")
logger.info(f"âœ… LINE Config: OK")
logger.info(f"ğŸ“… Using 2026 Gemini Models")
logger.info("="*60)

# âš ï¸ Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡ ÙÙ‚Ø· Ù„Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ø­Ù„ÙŠ
# Ø¹Ù„Ù‰ Render Ø³ÙŠØªÙ… ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¨ÙˆØ§Ø³Ø·Ø© gunicorn Ù…Ù† Procfile
if __name__ == "__main__":
    port = int(os.getenv('PORT', 5000))
    logger.info(f"ğŸƒ Running in development mode on port {port}")
    app.run(host='0.0.0.0', port=port, debug=False)
